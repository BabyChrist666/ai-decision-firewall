<div align="center">

```
 █████╗ ██████╗ ██╗   ██╗███████╗███████╗ █████╗ ██╗          ██████╗██╗██████╗  ██████╗██╗   ██╗██╗████████╗
██╔══██╗██╔══██╗╚██╗ ██╔╝██╔════╝██╔════╝██╔══██╗██║         ██╔════╝██║██╔══██╗██╔════╝██║   ██║██║╚══██╔══╝
███████║██████╔╝ ╚████╔╝ ███████╗███████╗███████║██║         ██║     ██║██████╔╝██║     ██║   ██║██║   ██║
██╔══██║██╔══██╗  ╚██╔╝  ╚════██║╚════██║██╔══██║██║         ██║     ██║██╔══██╗██║     ██║   ██║██║   ██║
██║  ██║██████╔╝   ██║   ███████║███████║██║  ██║███████╗    ╚██████╗██║██║  ██║╚██████╗╚██████╔╝██║   ██║
╚═╝  ╚═╝╚═════╝    ╚═╝   ╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝     ╚═════╝╚═╝╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚═╝   ╚═╝
```

# ◎ AI DECISION FIREWALL ◎

<img src="https://img.shields.io/badge/GOVERNANCE-RUNTIME-00ffff?style=for-the-badge&labelColor=001a1a" />
<img src="https://img.shields.io/badge/ENFORCEMENT-ACTIVE-00cccc?style=for-the-badge&labelColor=001a1a" />
<img src="https://img.shields.io/badge/MODE-ENTERPRISE-008888?style=for-the-badge&labelColor=001a1a" />
<img src="https://img.shields.io/badge/STATUS-INTERCEPTING-00aaaa?style=for-the-badge&labelColor=001a1a" />

<br/>

**`[ RUNTIME GOVERNANCE // POLICY ENFORCEMENT // AI SAFETY ]`**

*From the abyss, we guard the gates.*

```
    ╔═══════════════════════════════════════════════════════════════════════════╗
    ║                                                                           ║
    ║   ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   ║
    ║   ░░                                                                ░░   ║
    ║   ░░   AN ENTERPRISE-GRADE RUNTIME ENFORCEMENT LAYER THAT SITS      ░░   ║
    ║   ░░   BETWEEN AI SYSTEMS AND REAL-WORLD ACTIONS                    ░░   ║
    ║   ░░                                                                ░░   ║
    ║   ░░   INTERCEPT → EVALUATE → VERDICT → EXECUTE                     ░░   ║
    ║   ░░                                                                ░░   ║
    ║   ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   ║
    ║                                                                           ║
    ╚═══════════════════════════════════════════════════════════════════════════╝
```

</div>

---

## ◎ THE PROBLEM

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                                                                               ┃
┃   AI systems in production face critical challenges that traditional          ┃
┃   monitoring and post-hoc analysis cannot address:                            ┃
┃                                                                               ┃
┃   ▸ HALLUCINATIONS         Models express high confidence without evidence    ┃
┃   ▸ OVERCONFIDENCE         High scores assigned to speculative outputs        ┃
┃   ▸ HIGH-RISK ACTIONS      Autonomous execution without human oversight       ┃
┃   ▸ LACK OF AUDITABILITY   No explanation or immutable trail                  ┃
┃                                                                               ┃
┃   ADF enforces governance at runtime, BEFORE AI outputs become actions.       ┃
┃                                                                               ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
```

---

## ◎ ENFORCEMENT DIMENSIONS

<table>
<tr>
<td width="50%">

### ◎ VALIDATION LAYER

```
┌────────────────────────────────┐
│  ▸ Evidence Validation         │
│    Require sources for claims  │
│                                │
│  ▸ Confidence Alignment        │
│    Validate score accuracy     │
│                                │
│  ▸ Risk Assessment             │
│    Calculate impact scores     │
└────────────────────────────────┘
```

</td>
<td width="50%">

### ◎ ENFORCEMENT LAYER

```
┌────────────────────────────────┐
│  ▸ Policy Enforcement          │
│    Non-bypassable rules        │
│                                │
│  ▸ Safety Rules                │
│    Block harmful patterns      │
│                                │
│  ▸ Audit Logging               │
│    Immutable decision trail    │
└────────────────────────────────┘
```

</td>
</tr>
</table>

---

## ◎ VERDICT ENGINE

```
                    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
                    ┃               AI OUTPUT RECEIVED               ┃
                    ┗━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                          │
                                          ▼
                    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
                    ┃          ◎ ADF EVALUATION ENGINE ◎            ┃
                    ┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┫
                    ┃  ▸ Claim Parser                               ┃
                    ┃  ▸ Evidence Checker                           ┃
                    ┃  ▸ Confidence Validator                       ┃
                    ┃  ▸ Risk Scorer                                ┃
                    ┃  ▸ Rules Engine                               ┃
                    ┃  ▸ Verdict Engine                             ┃
                    ┗━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                          │
                    ┌─────────────────────┼─────────────────────┐
                    │                     │                     │
                    ▼                     ▼                     ▼
    ┏━━━━━━━━━━━━━━━━━━━━┓  ┏━━━━━━━━━━━━━━━━━━━━┓  ┏━━━━━━━━━━━━━━━━━━━━┓
    ┃      ◎ ALLOW       ┃  ┃    ◎ ESCALATE      ┃  ┃      ◎ BLOCK       ┃
    ┃                    ┃  ┃                    ┃  ┃                    ┃
    ┃  All checks pass   ┃  ┃  Human review      ┃  ┃  Safety violation  ┃
    ┃  Risk acceptable   ┃  ┃  Evidence needed   ┃  ┃  Cannot proceed    ┃
    ┗━━━━━━━━━━━━━━━━━━━━┛  ┗━━━━━━━━━━━━━━━━━━━━┛  ┗━━━━━━━━━━━━━━━━━━━━┛
```

---

## ◎ VERDICT TYPES

| VERDICT | MEANING | ACTION |
|:--------|:--------|:-------|
| **`ALLOW`** | All checks passed, risk acceptable | Output may proceed |
| **`REQUIRE_EVIDENCE`** | Missing supporting sources | Must provide evidence before proceeding |
| **`REQUIRE_HUMAN_REVIEW`** | Policy mandates oversight | Human approval required |
| **`BLOCK`** | Safety rules violated | Output cannot proceed |

---

## ◎ POLICY MODES

<table>
<tr>
<td width="50%">

### GENERAL_AI

```
╔══════════════════════════════════╗
║  Default conservative policy     ║
║                                  ║
║  ▸ Human review: trades, code    ║
║  ▸ Standard evidence thresholds  ║
║  ▸ Balanced risk tolerance       ║
╚══════════════════════════════════╝
```

### FINANCIAL_SERVICES

```
╔══════════════════════════════════╗
║  All trades require review       ║
║                                  ║
║  ▸ MANDATORY human review        ║
║  ▸ Strict evidence requirements  ║
║  ▸ Low risk tolerance            ║
╚══════════════════════════════════╝
```

</td>
<td width="50%">

### HEALTHCARE

```
╔══════════════════════════════════╗
║  Medical actions require review  ║
║                                  ║
║  ▸ MANDATORY human review        ║
║  ▸ Highest evidence thresholds   ║
║  ▸ Strictest risk enforcement    ║
╚══════════════════════════════════╝
```

### LEGAL

```
╔══════════════════════════════════╗
║  Legal actions require review    ║
║                                  ║
║  ▸ MANDATORY human review        ║
║  ▸ Highest evidence thresholds   ║
║  ▸ Strictest risk enforcement    ║
╚══════════════════════════════════╝
```

</td>
</tr>
</table>

---

## ◎ SYSTEM ARCHITECTURE

```
┌─────────────────────┐
│     AI SYSTEM       │
│    (LLM/Model)      │
└──────────┬──────────┘
           │
           │ AI Output + Metadata
           │ (confidence, action, sources)
           │
           ▼
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                  ◎ AI DECISION FIREWALL ◎                        ┃
┃                                                                  ┃
┃   ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓   ┃
┃   ┃                   Policy Manager                        ┃   ┃
┃   ┃                 (Governance Rules)                      ┃   ┃
┃   ┗━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛   ┃
┃                          │                                       ┃
┃   ┏━━━━━━━━━━━━━━━━━━━━━━▼━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓   ┃
┃   ┃              Firewall Interceptor                       ┃   ┃
┃   ┃   ▸ Claim Parser        ▸ Evidence Checker              ┃   ┃
┃   ┃   ▸ Confidence Valid    ▸ Risk Scorer                   ┃   ┃
┃   ┃   ▸ Rules Engine        ▸ Verdict Engine                ┃   ┃
┃   ┗━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛   ┃
┃                          │                                       ┃
┃   ┏━━━━━━━━━━━━━━━━━━━━━━▼━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓   ┃
┃   ┃               Audit & Metrics                           ┃   ┃
┃   ┃   ▸ Immutable Logs      ▸ Decision Tracking             ┃   ┃
┃   ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛   ┃
┃                                                                  ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                           │
                           │ Verdict + Explanation
                           │
           ┌───────────────┴───────────────┐
           │                               │
           ▼                               ▼
    ┌─────────────┐                 ┌─────────────┐
    │   ALLOW     │                 │   BLOCK /   │
    │             │                 │   ESCALATE  │
    └──────┬──────┘                 └─────────────┘
           │
           ▼
    ┌─────────────────┐
    │  REAL-WORLD     │
    │    ACTION       │
    └─────────────────┘
```

---

## ◎ QUICK START

### PREREQUISITES

```
╔════════════════════════════════════════════════════════════╗
║  ▸ Python 3.8+                                             ║
║  ▸ pip package manager                                     ║
╚════════════════════════════════════════════════════════════╝
```

### INSTALLATION

```bash
# Clone the repository
git clone https://github.com/BabyChrist666/ai-decision-firewall.git
cd ai-decision-firewall

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### EXECUTE

```bash
# Run with uvicorn
uvicorn adf.main:app --reload --host 0.0.0.0 --port 8000

# Or use Python module
python -m adf.main
```

### VERIFY

```bash
# Health check
curl http://localhost:8000/health

# API Documentation
# → http://localhost:8000/docs
# → http://localhost:8000/redoc
```

---

## ◎ API ENDPOINTS

### Core Endpoints

| ENDPOINT | METHOD | DESCRIPTION |
|:---------|:------:|:------------|
| `/firewall/check` | POST | Evaluate AI output, return verdict |
| `/policy/mode` | POST | Set governance policy mode |
| `/policy/mode` | GET | Get current policy configuration |
| `/audit/logs` | GET | Query audit logs (enterprise) |
| `/metrics` | GET | Get firewall statistics |
| `/demo/run` | POST | Execute demo scenarios |

---

## ◎ USAGE EXAMPLE

### Firewall Check Request

```bash
curl -X POST http://localhost:8000/firewall/check \
  -H "Content-Type: application/json" \
  -d '{
    "ai_output": "Execute trade: BUY 1000 shares of AAPL",
    "confidence": 0.92,
    "intended_action": "trade",
    "sources": []
  }'
```

### Response

```json
{
  "verdict": "REQUIRE_HUMAN_REVIEW",
  "reason": "Governance rule: trade actions require mandatory human review",
  "risk_score": 0.75,
  "explanation": "This trade action requires mandatory human review...",
  "applied_policies": ["mandatory_governance_review"],
  "escalation_reason": "Governance rule: trade actions require mandatory human review",
  "confidence_alignment": false,
  "failed_checks": ["governance_mandatory_review"],
  "details": {
    "claims": [...],
    "risk_level": "high",
    "checks": {...}
  }
}
```

### Set Policy Mode

```bash
curl -X POST http://localhost:8000/policy/mode \
  -H "Content-Type: application/json" \
  -d '{"mode": "FINANCIAL_SERVICES"}'
```

---

## ◎ SDK USAGE

### Basic Usage

```python
from adf.sdk import FirewallClient

client = FirewallClient()

response = client.check(
    ai_output="Execute trade: BUY 1000 shares of AAPL",
    confidence=0.9,
    intended_action="trade",
    sources=["https://analysis.com/report"]
)

if response.verdict == "ALLOW":
    execute_trade(response.ai_output)
elif response.verdict == "REQUIRE_HUMAN_REVIEW":
    escalate_for_review(response)
else:
    handle_blocked_output(response)
```

### Decorator Pattern

```python
from adf.sdk import firewalled

@firewalled(intended_action="trade", raise_on_block=True)
def execute_trading_strategy():
    ai_output = llm.generate("Should I buy AAPL?")
    confidence = 0.85
    sources = ["https://financial-analysis.com/report"]

    return ai_output, confidence, sources

try:
    result = execute_trading_strategy()
except RuntimeError as e:
    print(f"Governance decision: {e}")
```

---

## ◎ ENTERPRISE FEATURES

| FEATURE | DESCRIPTION |
|:--------|:------------|
| **Audit Logging** | Immutable JSONL logs for compliance |
| **Metrics & Analytics** | Track decisions, block rates, escalations |
| **Self-Learning** | Adaptive threshold tuning from overrides |
| **Policy Modes** | Industry-specific governance profiles |

---

## ◎ CONFIGURATION

### Environment Variables

| VARIABLE | DESCRIPTION |
|:---------|:------------|
| `ADF_ENTERPRISE_MODE` | Enable enterprise features |
| `ADF_AUDIT_LOG_DIR` | Directory for audit logs |
| `ADF_MEMORY_DIR` | Directory for learning memory |
| `ADF_METRICS_DIR` | Directory for metrics storage |

---

## ◎ TESTING

```bash
# Run the test suite
pytest test_example.py test_enterprise.py test_governance_rules.py -v
```

---

## ◎ DIRECTORY STRUCTURE

```
ai-decision-firewall/
├── adf/
│   ├── main.py              # FastAPI application
│   ├── firewall.py          # Core firewall logic
│   ├── policy.py            # Policy management
│   ├── evidence.py          # Evidence validation
│   ├── risk.py              # Risk scoring
│   ├── audit.py             # Audit logging
│   ├── sdk.py               # Python SDK
│   └── config.py            # Configuration
├── tests/                   # Test suite
├── adf_dashboard.html       # Demo dashboard
├── requirements.txt
└── README.md
```

---

## ◎ TARGET AUDIENCE

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                                                                               ┃
┃   ▸ ENTERPRISES                                                               ┃
┃     Organizations deploying AI that require governance and risk management    ┃
┃                                                                               ┃
┃   ▸ REGULATED INDUSTRIES                                                      ┃
┃     Finance, healthcare, legal with compliance requirements                   ┃
┃                                                                               ┃
┃   ▸ AI PRODUCT TEAMS                                                          ┃
┃     Engineering teams building AI products needing runtime enforcement        ┃
┃                                                                               ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
```

---

## ◎ TECH STACK

<table>
<tr>
<td align="center"><strong>FastAPI</strong><br/>Async Server</td>
<td align="center"><strong>Python</strong><br/>3.8+ Runtime</td>
<td align="center"><strong>Pydantic</strong><br/>Validation</td>
<td align="center"><strong>JSONL</strong><br/>Audit Logs</td>
</tr>
</table>

---

<div align="center">

```
╔═══════════════════════════════════════════════════════════════════════════════════╗
║                                                                                   ║
║   ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   ║
║   ░░                                                                        ░░   ║
║   ░░    AI MUST BE GOVERNED, NOT JUST OPTIMIZED                             ░░   ║
║   ░░                                                                        ░░   ║
║   ░░    ADF provides the runtime enforcement layer that enterprises         ░░   ║
║   ░░    need to deploy AI systems safely, accountably, and in               ░░   ║
║   ░░    compliance with regulatory requirements.                            ░░   ║
║   ░░                                                                        ░░   ║
║   ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░   ║
║                                                                                   ║
╚═══════════════════════════════════════════════════════════════════════════════════╝
```

**MIT License**

*From the abyss, we enforce the boundaries of artificial minds.*

</div>
